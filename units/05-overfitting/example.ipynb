{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Unit 5 - Overfitting - Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting is a scary thing. \n",
    "\n",
    "It is generally where contact with reality breaks the pretty illusions of the data scientist about how brilliant (s)he is, and keeps one's ego in check. \n",
    "\n",
    "There are a number of ways to reduce overfitting (Regularization, proper setting of hyper parameters, bagging, etc), but the first step is always to diagnose its presence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact   # <-- did you know you could do this in jupyter? Is that cool or what? \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from bokeh.plotting import figure, output_notebook\n",
    "from utils import load_data, visualizations\n",
    "from sklearn.model_selection import cross_val_score\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get our Ying Yang dataset again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data.get_ying_yang(200)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at it with 2 neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizations.plot_data(model=KNeighborsClassifier(2), \n",
    "                     data=data, \n",
    "                     target='c', \n",
    "                     feature1='a', \n",
    "                     feature2='b', \n",
    "                     out_of_sample=False, \n",
    "                     probabilities=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks fine actually, but why are we allowing those errors to go unchallenged? Maybe switching to 1 Neighbour would actually catch all of them? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizations.plot_data(model=KNeighborsClassifier(1), \n",
    "                     data=data, \n",
    "                     target='c', \n",
    "                     feature1='a', \n",
    "                     feature2='b', \n",
    "                     out_of_sample=False, \n",
    "                     probabilities=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brilliant! We have the perfect model! Except of course we know that this isn't the real distribution that we want, we're just overfitting the training set. So what would happen if we were to train on half of the dataset, and save the other half for evaluation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizations.plot_data(model=KNeighborsClassifier(1), \n",
    "                     data=data, \n",
    "                     target='c', \n",
    "                     feature1='a', \n",
    "                     feature2='b', \n",
    "                     out_of_sample=True, # <--- I kept everything else the same, but changed this to True    \n",
    "                     probabilities=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can clearly see the overfit. The separate red blob in the middle is the result of overfitting some noise. We also have a slightly worse model because we have less data to train on (we just trained on 50% this time), but we can control for that by doubling the dataset size: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data.get_ying_yang(400)  # <-- this was 200 in the original dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(1)\n",
    "\n",
    "visualizations.plot_data(model=model, \n",
    "                         data=data, \n",
    "                         target='c', \n",
    "                         feature1='a', \n",
    "                         feature2='b', \n",
    "                         out_of_sample=True,  \n",
    "                         probabilities=False)\n",
    "\n",
    "print('CV score: %0.2f' % cross_val_score(estimator=model, \n",
    "                X=data[['a', 'b']], \n",
    "                y=data['c']).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, dramatically overfit. What if we changed this to use 2 neigbors? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(2)\n",
    "\n",
    "visualizations.plot_data(model=model, \n",
    "                         data = load_data.get_ying_yang(400), # <-- this was 200 in the original dataset  \n",
    "                         target='c', \n",
    "                         feature1='a', \n",
    "                         feature2='b', \n",
    "                         out_of_sample=True,  \n",
    "                         probabilities=False)\n",
    "\n",
    "print('CV score: %0.2f' % cross_val_score(estimator=model, \n",
    "                X=data[['a', 'b']], \n",
    "                y=data['c']).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better... but still way too much variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, handtuning is boring. Let's use Jupyter Interact! (If it doesn't work first time, try [this](http://ipywidgets.readthedocs.io/en/stable/user_install.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s(n_neighbors):\n",
    "    visualizations.plot_data(model=KNeighborsClassifier(n_neighbors=n_neighbors), \n",
    "                     data=data, \n",
    "                     target='c', \n",
    "                     feature1='a', \n",
    "                     feature2='b', \n",
    "                     out_of_sample=True, \n",
    "                     probabilities=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "interact(s, n_neighbors=(1, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see this with a different model: the [RandomForestClassifier](scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), which is naturally more resistant to overfitting: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s(max_depth, n_estimators):\n",
    "    visualizations.plot_data(model=RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators), \n",
    "                         data=data, \n",
    "                         target='c', \n",
    "                         feature1='a', \n",
    "                         feature2='b', \n",
    "                         out_of_sample=True, \n",
    "                         probabilities=False)\n",
    "    \n",
    "interact(s, max_depth=(1, 15), n_estimators=(10, 100, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
