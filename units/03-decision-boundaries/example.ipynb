{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Unit 3 - Decision Boundaries - Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you know those movies where someone mentions [says the title of the movie](https://youtu.be/0V1sYNvKZt8?t=13s), and you go \"ooh, that was the name!\", well we've reached that stage. \n",
    "\n",
    "Decision boundaries are useful, and beautiful. Let's jump in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "output_notebook()\n",
    "\n",
    "from utils import load_data, visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual we're going to take a toy dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data.get_ying_yang()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can (and always should) look at a snapshot and some descriptive statistics before getting stuck into the fun stuff: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()  # this gets a lot of descriptive statistics in one go "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's observe what we're working with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizations.plot_data(data=data, \n",
    "                        target='c', \n",
    "                        feature1='a',\n",
    "                        feature2='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha, so the dataset is a kind of \"ying-yang\" simbol. This looks like a job for the [KNearestNeighborsClassifier](http://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(3)  # instanciating a model with 3 neigbors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for the visualization. I'll take the previously used ``plot_data``, but this time I'll pass it our model too. It will fit it on all the data ([I know, I know](https://i.giphy.com/media/G8G7xjKlcPRni/giphy.webp), more on that later). \n",
    "\n",
    "It will then create a fine mesh of all possible points, and predict them. That means that we can have decision boundaries in areas where there is no training data. Finally, it prints the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizations.plot_data(data=data, \n",
    "                        target='c', \n",
    "                        feature1='a',\n",
    "                        feature2='b', \n",
    "                        model=model)  # <--- plot the decision boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cooooool! \n",
    "\n",
    "Now you might be thinking: _\"That's all very fine, but I don't care about it being 25% green, things are either green or not. This is classification, and I want to know what the decision is. Stop hedging your bets you spineless algorithm, I need answers god damn it!\"_\n",
    "\n",
    "Ok. Let's set probabilities to False then. Jeez. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizations.plot_data(data=data, \n",
    "                        target='c', \n",
    "                        feature1='a',\n",
    "                        feature2='b', \n",
    "                        model=model, \n",
    "                        probabilities=False)  # <--- Yay or nay! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggestion: try moving the number of neigbors around, and see what happens. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Once you're done, go on to the exercise! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
